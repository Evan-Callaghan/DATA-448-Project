{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name plot_tree",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e93759e336b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name plot_tree"
     ]
    }
   ],
   "source": [
    "## Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pd.set_option('display.max_columns', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the data set\n",
    "train = pd.read_csv('/Users/EvanCallaghan/Documents/Courses/Predictive Analytics/DATA-448-Project/Data/diabetes_train.csv')\n",
    "\n",
    "## Printing the first five observations\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train['BMI'], bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train['GenHlth'], bins = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train['MentHlth'], bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train['PhysHlth'], bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train['Age'], bins = 8, edgecolor = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train['Education'], bins = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train['Income'], bins = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BMI Categoricals\n",
    "\n",
    "train['BMI_Underweight'] = np.where(train['BMI'] < 18.5, 1, 0)\n",
    "train['BMI_Healthy'] = np.where((train['BMI'] >= 18.5) & (train['BMI'] < 25), 1, 0)\n",
    "train['BMI_Overweight'] = np.where((train['BMI'] >= 25) & (train['BMI'] < 30), 1, 0)\n",
    "train['BMI_Obese'] = np.where(train['BMI'] >= 30, 1, 0)\n",
    "\n",
    "\n",
    "## Log(BMI)\n",
    "train['Log_BMI'] = np.log(train['BMI'])\n",
    "\n",
    "\n",
    "## Creating dummy variables for Sex, Education, and Income\n",
    "\n",
    "train = pd.concat([train.drop(columns = ['Sex']), pd.get_dummies(train['Sex'])], axis = 1)\n",
    "train = train.rename(columns = { 0: 'Female', 1: 'Male'})\n",
    "\n",
    "train = pd.concat([train.drop(columns = ['Education']), pd.get_dummies(train['Education'])], axis = 1)\n",
    "train = train.rename(columns = { 1: 'Never_Attended', 2: 'Grades_1_8', 3: 'Grades_9_11', 4: 'GED', 5: 'College_1_3', \n",
    "                              6: 'College_4+'})\n",
    "\n",
    "train = pd.concat([train.drop(columns = ['Income']), pd.get_dummies(train['Income'])], axis = 1)\n",
    "train = train.rename(columns = { 1: '<10,000', 2: '<15,000', 3: '<20,000', 4: '<25,000', 5: '<35,000', \n",
    "                                      6: '<50,000',  7: '<75,000',  8: '75,000+'})\n",
    "\n",
    "\n",
    "## Fruits and Veggies\n",
    "train['Fruits+Veggies'] = np.where((train['Fruits'] == 1) & (train['Veggies'] == 1), 1, 0)\n",
    "\n",
    "## Health care issues\n",
    "train['HealthCareIssues'] = np.where((train['AnyHealthcare'] == 0) & (train['NoDocbcCost'] == 0), 1, 0)\n",
    "\n",
    "## Poor diet\n",
    "train['PoorDiet'] = np.where((train['Fruits'] == 0) & (train['Veggies'] == 0) & \n",
    "                                (train['HvyAlcoholConsump'] == 1), 1, 0)\n",
    "\n",
    "\n",
    "train['MentHlth_cat'] = np.where((train.MentHlth <=10), 0, \n",
    "                                 np.where((train.MentHlth > 10) & (train.MentHlth <= 20), 1, 2))\n",
    "\n",
    "train['PhysHlth_cat'] = np.where((train.PhysHlth <=10), 0, \n",
    "                              np.where((train.PhysHlth > 10) & (train.PhysHlth <= 20), 1, 2))\n",
    "\n",
    "train['GenHlth_cat'] = np.where((train.GenHlth <=2), 0, \n",
    "                             np.where((train.GenHlth > 3) & (train.GenHlth <= 5), 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating variable importance scores\n",
    "\n",
    "## Defining the input and target variables\n",
    "X = train.drop(columns = ['Diabetes_012'])\n",
    "Y = train['Diabetes_012']\n",
    "\n",
    "## Defining a list to store results\n",
    "results = []\n",
    "\n",
    "## Repeating process 100 times\n",
    "for i in tqdm(range(0, 25)):\n",
    "    \n",
    "    ## Splitting the data\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "    \n",
    "    ## Building the model\n",
    "    OneVsRest_md = OneVsRestClassifier(estimator = RandomForestClassifier(max_depth = 3, \n",
    "                                                                   n_estimators = 500)).fit(X_train, Y_train)\n",
    "    \n",
    "    ## Appending feature importance results\n",
    "    for md in OneVsRest_md.estimators_:\n",
    "        \n",
    "        ## Extracting the scores from each model\n",
    "        results.append(md.feature_importances_)\n",
    "\n",
    "    \n",
    "\n",
    "## Changing results list to a dataframe\n",
    "results = pd.DataFrame(results, columns = X.columns)\n",
    "\n",
    "## Computing averages and sorting variables by importance\n",
    "results = pd.DataFrame(results.apply(np.mean, axis = 0))\n",
    "results = pd.DataFrame({'Feature': results.index, 'Importance': results[0].values}).sort_values(by = 'Importance', ascending = False)\n",
    "\n",
    "## Printing the 10 most important variables\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating interactions\n",
    "\n",
    "train['Interaction_1'] = train['HighBP'] * train['GenHlth']\n",
    "\n",
    "train['Interaction_2'] = train['HighBP'] * train['GenHlth_cat']\n",
    "\n",
    "train['Interaction_3'] = train['HighBP'] * train['HighChol']\n",
    "\n",
    "train['Interaction_4'] = train['GenHlth'] * train['GenHlth_cat']\n",
    "\n",
    "train['Interaction_5'] = train['GenHlth'] * train['HighChol']\n",
    "\n",
    "train['Interaction_6'] = train['GenHlth_cat'] * train['HighChol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a plot tree to engineer more interactions\n",
    "\n",
    "## Defining the input and target variables\n",
    "X = train.drop(columns = ['Diabetes_012'])\n",
    "Y = train['Diabetes_012']\n",
    "\n",
    "## Splitting the data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, stratify = Y)\n",
    "\n",
    "## Building a decision tree model with max depth = 3 on the train data-frame\n",
    "tree_md = DecisionTreeClassifier(max_depth = 3).fit(X_train, Y_train)\n",
    "\n",
    "## Visualizing the decision tree model and identify any interesting interactions/features\n",
    "fig = plt.figure(figsize = (20, 20))\n",
    "plot_tree(tree_md, feature_names = X.columns, filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating tree interactions\n",
    "\n",
    "train['Tree_1'] = np.where((train['Interaction_2'] <= 0.5) & (train['Interaction_5'] <= 1.5) & (train['Age'] <= 8.5), 1, 0)\n",
    "\n",
    "train['Tree_2'] = np.where((train['Interaction_2'] <= 0.5) & (train['Interaction_5'] <= 1.5) & (train['Age'] > 8.5), 1, 0)\n",
    "\n",
    "train['Tree_3'] = np.where((train['Interaction_2'] <= 0.5) & (train['Interaction_5'] > 1.5) & (train['Log_BMI'] <= 3.384), 1, 0)\n",
    "\n",
    "train['Tree_4'] = np.where((train['Interaction_2'] <= 0.5) & (train['Interaction_5'] > 1.5) & (train['Log_BMI'] > 3.384), 1, 0)\n",
    "\n",
    "train['Tree_5'] = np.where((train['Interaction_2'] > 0.5) & (train['Interaction_5'] <= 3.5) & (train['BMI'] <= 30.5), 1, 0)\n",
    "\n",
    "train['Tree_6'] = np.where((train['Interaction_2'] > 0.5) & (train['Interaction_5'] <= 3.5) & (train['BMI'] > 30.5), 1, 0)\n",
    "\n",
    "train['Tree_7'] = np.where((train['Interaction_2'] > 0.5) & (train['Interaction_5'] > 3.5) & (train['Log_BMI'] <= 3.481), 1, 0)\n",
    "\n",
    "train['Tree_8'] = np.where((train['Interaction_2'] > 0.5) & (train['Interaction_5'] > 3.5) & (train['Log_BMI'] > 3.481), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p27",
   "language": "python",
   "name": "conda_amazonei_mxnet_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
