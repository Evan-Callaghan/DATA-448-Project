{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier with the top 6 featues\n",
      "Model:  RandomForestClassifier(max_depth=5, min_samples_leaf=5, min_samples_split=10,\n",
      "                       n_estimators=300)\n",
      "Score:  0.865\n",
      " \n",
      " \n",
      "Random Forest Classifier with the top 7 featues\n",
      "Model:  RandomForestClassifier(max_depth=7, min_samples_leaf=5, min_samples_split=15,\n",
      "                       n_estimators=300)\n",
      "Score:  0.862\n",
      " \n",
      " \n",
      "Random Forest Classifier with the top 8 featues\n",
      "Model:  RandomForestClassifier(max_depth=7, min_samples_leaf=5, min_samples_split=15,\n",
      "                       n_estimators=300)\n",
      "Score:  0.865\n",
      " \n",
      " \n",
      "AdaBoost Classifier with the top 6 features\n",
      "Model:  AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,\n",
      "                                                         min_samples_leaf=5,\n",
      "                                                         min_samples_split=10),\n",
      "                   learning_rate=0.001, n_estimators=100)\n",
      "Score:  0.87\n",
      " \n",
      " \n",
      "AdaBoost Classifier with the top 7 features\n",
      "Model:  AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,\n",
      "                                                         min_samples_leaf=5,\n",
      "                                                         min_samples_split=10),\n",
      "                   learning_rate=0.001, n_estimators=500)\n",
      "Score:  0.869\n",
      " \n",
      " \n",
      "AdaBoost Classifier with the top 8 features\n",
      "Model:  AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,\n",
      "                                                         min_samples_leaf=5,\n",
      "                                                         min_samples_split=10),\n",
      "                   learning_rate=0.001, n_estimators=500)\n",
      "Score:  0.875\n",
      " \n",
      " \n",
      "Decision Tree Classifier with the top 6 features\n",
      "Model:  DecisionTreeClassifier(max_depth=3, min_samples_leaf=5, min_samples_split=10)\n",
      "Score:  0.864\n",
      " \n",
      " \n",
      "Decision Tree Classifier with the top 7 features\n",
      "Model:  DecisionTreeClassifier(max_depth=3, min_samples_leaf=5, min_samples_split=10)\n",
      "Score:  0.86\n",
      " \n",
      " \n",
      "Decision Tree Classifier with the top 8 features\n",
      "Model:  DecisionTreeClassifier(max_depth=3, min_samples_leaf=5, min_samples_split=10)\n",
      "Score:  0.856\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "## Importing libraries\n",
    "import pandas as pd; pd.set_option('display.max_columns', 50)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import confusion_matrix, classification_report, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "\n",
    "## Reading the data set\n",
    "train = pd.read_csv('/Users/gabrielvictorgomesferreira/Desktop/Diabetes_Project/Data/Final_Var_Eng_train.csv')\n",
    "\n",
    "train = train.iloc[0:1000,:]\n",
    "\n",
    "# Defining input and target variables\n",
    "X = train.drop(['Diabetes_012'], axis = 1)\n",
    "Y = train['Diabetes_012']\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "\n",
    "\n",
    "# Defining top 8, 7, and 6 variables\n",
    "# Train dataset Random Forest Classifier\n",
    "RF_X_train_8 = X_train[['Interaction_1', 'Log_BMI', 'PhysHlth', 'MentHlth', 'Fruits', 'Age', 'Smoker', 'College_1_3']]\n",
    "RF_X_train_7 = X_train[['Interaction_1', 'Log_BMI', 'PhysHlth', 'MentHlth', 'Fruits', 'Age', 'Smoker']]\n",
    "RF_X_train_6 = X_train[['Interaction_1', 'Log_BMI', 'PhysHlth', 'MentHlth', 'Fruits', 'Age']]\n",
    "\n",
    "\n",
    "\n",
    "## Defining the hyper-parameters for Random Forest Classifier\n",
    "RF_param_grid = {'n_estimators': [100, 300, 500],\n",
    "                 'min_samples_split': [10, 15], \n",
    "                 'min_samples_leaf': [5, 7], \n",
    "                 'max_depth' : [3, 5, 7]}\n",
    "\n",
    "# Performing GridSearch\n",
    "RF_grid_search_6 = GridSearchCV(RandomForestClassifier(), RF_param_grid, cv = 3, scoring = 'f1_micro', n_jobs = -1).fit(RF_X_train_6, Y_train)\n",
    "RF_grid_search_7 = GridSearchCV(RandomForestClassifier(), RF_param_grid, cv = 3, scoring = 'f1_micro', n_jobs = -1).fit(RF_X_train_7, Y_train)\n",
    "RF_grid_search_8 = GridSearchCV(RandomForestClassifier(), RF_param_grid, cv = 3, scoring = 'f1_micro', n_jobs = -1).fit(RF_X_train_8, Y_train)\n",
    "\n",
    "\n",
    "# Extracting the best model\n",
    "RF_model_6 = RF_grid_search_6.best_estimator_\n",
    "RF_score_6 = RF_grid_search_6.cv_results_\n",
    "RF_score_6 = RF_score_6['mean_test_score'][0]\n",
    "\n",
    "# Printing the results\n",
    "print(\"Random Forest Classifier with the top 6 featues\")\n",
    "print(\"Model: \", RF_model_6)\n",
    "print(\"Score: \", round(RF_score_6, 3))\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "# Extracting the best model\n",
    "RF_model_7 = RF_grid_search_7.best_estimator_\n",
    "RF_score_7 = RF_grid_search_7.cv_results_\n",
    "RF_score_7 = RF_score_7['mean_test_score'][0]\n",
    "\n",
    "# Printing the results\n",
    "print(\"Random Forest Classifier with the top 7 featues\")\n",
    "print(\"Model: \", RF_model_7)      \n",
    "print(\"Score: \", round(RF_score_7, 3))\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "# Extracting the best model\n",
    "RF_model_8 = RF_grid_search_8.best_estimator_\n",
    "RF_score_8 = RF_grid_search_8.cv_results_\n",
    "RF_score_8 = RF_score_8['mean_test_score'][0]\n",
    "\n",
    "# Printing the results\n",
    "print(\"Random Forest Classifier with the top 8 featues\")\n",
    "print(\"Model: \", RF_model_8)\n",
    "print(\"Score: \", round(RF_score_8, 3))\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "## Defining the hyper-parameters for Ada\n",
    "# Train dataset AdaBoost with Decision Tree Classifier\n",
    "Ada_X_train_8 = X_train[['Interaction_1', 'Log_BMI', 'Veggies', 'Stroke', 'Smoker', 'Age', 'PhysHlth', 'Interaction_5']]\n",
    "Ada_X_train_7 = X_train[['Interaction_1', 'Log_BMI', 'Veggies', 'Stroke', 'Smoker', 'Age', 'PhysHlth']]\n",
    "Ada_X_train_6 = X_train[['Interaction_1', 'Log_BMI', 'Veggies', 'Stroke', 'Smoker', 'Age']]\n",
    "\n",
    "\n",
    "Ada_param_grid = {'n_estimators': [100, 300, 500],\n",
    "                 'base_estimator__min_samples_split': [10, 15], \n",
    "                 'base_estimator__min_samples_leaf': [5, 7], \n",
    "                 'base_estimator__max_depth' : [3, 5, 7],\n",
    "                 'learning_rate': [0.001, 0.01, 0.1]}\n",
    "\n",
    "## Running grid search with 3 fold\n",
    "Ada_grid_search_6 = GridSearchCV(AdaBoostClassifier(base_estimator = DecisionTreeClassifier()), Ada_param_grid, cv = 3, scoring = 'f1_micro', n_jobs = -1).fit(Ada_X_train_6, Y_train)\n",
    "Ada_grid_search_7 = GridSearchCV(AdaBoostClassifier(base_estimator = DecisionTreeClassifier()), Ada_param_grid, cv = 3, scoring = 'f1_micro', n_jobs = -1).fit(Ada_X_train_7, Y_train)\n",
    "Ada_grid_search_8 = GridSearchCV(AdaBoostClassifier(base_estimator = DecisionTreeClassifier()), Ada_param_grid, cv = 3, scoring = 'f1_micro', n_jobs = -1).fit(Ada_X_train_8, Y_train)\n",
    "\n",
    "# Extracting the best model\n",
    "Ada_model_6 = Ada_grid_search_6.best_estimator_\n",
    "Ada_score_6 = Ada_grid_search_6.cv_results_\n",
    "Ada_score_6 = Ada_score_6['mean_test_score'][0]\n",
    "\n",
    "# Printing the results\n",
    "print(\"AdaBoost Classifier with the top 6 features\")\n",
    "print(\"Model: \", Ada_model_6)\n",
    "print(\"Score: \", round(Ada_score_6, 3))\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "# Extracting the best model\n",
    "Ada_model_7 = Ada_grid_search_7.best_estimator_\n",
    "Ada_score_7 = Ada_grid_search_7.cv_results_\n",
    "Ada_score_7 = Ada_score_7['mean_test_score'][0]\n",
    "\n",
    "# Printing the results\n",
    "print(\"AdaBoost Classifier with the top 7 features\")\n",
    "print(\"Model: \", Ada_model_7)\n",
    "print(\"Score: \", round(Ada_score_7, 3))\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "# Extracting the best model\n",
    "Ada_model_8 = Ada_grid_search_8.best_estimator_\n",
    "Ada_score_8 = Ada_grid_search_8.cv_results_\n",
    "Ada_score_8 = Ada_score_8['mean_test_score'][0]\n",
    "\n",
    "# Printing the results\n",
    "print(\"AdaBoost Classifier with the top 8 features\")\n",
    "print(\"Model: \", Ada_model_8)\n",
    "print(\"Score: \", round(Ada_score_8, 3))\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "# Defining top 8, 7, and 6 variables\n",
    "# Train dataset Decision Tree Classifier\n",
    "Tree_X_train_8 = X_train[['Interaction_1', 'Log_BMI', 'Veggies', 'Smoker', 'PhysActivity', 'MentHlth', 'Interaction_5', 'HeartDiseaseorAttack']]\n",
    "Tree_X_train_7 = X_train[['Interaction_1', 'Log_BMI', 'Veggies', 'Smoker', 'PhysActivity', 'MentHlth', 'Interaction_5']]\n",
    "Tree_X_train_6 = X_train[['Interaction_1', 'Log_BMI', 'Veggies', 'Smoker', 'PhysActivity', 'MentHlth']]\n",
    "\n",
    "\n",
    "\n",
    "## Defining the hyper-parameters for Decision Tree Classifier\n",
    "tree_param_grid = {'min_samples_split': [10, 15], \n",
    "                 'min_samples_leaf': [5, 7], \n",
    "                 'max_depth' : [3, 5, 7]}\n",
    "\n",
    "# Performing GridSearch\n",
    "tree_grid_search_6 = GridSearchCV(DecisionTreeClassifier(), tree_param_grid, cv = 3, scoring = 'f1_micro', n_jobs = -1).fit(Tree_X_train_6, Y_train)\n",
    "tree_grid_search_7 = GridSearchCV(DecisionTreeClassifier(), tree_param_grid, cv = 3, scoring = 'f1_micro', n_jobs = -1).fit(Tree_X_train_7, Y_train)\n",
    "tree_grid_search_8 = GridSearchCV(DecisionTreeClassifier(), tree_param_grid, cv = 3, scoring = 'f1_micro', n_jobs = -1).fit(Tree_X_train_8, Y_train)\n",
    "\n",
    "# Extracting the best model\n",
    "Tree_model_6 = tree_grid_search_6.best_estimator_\n",
    "Tree_score_6 = tree_grid_search_6.cv_results_\n",
    "Tree_score_6 = Tree_score_6['mean_test_score'][0]\n",
    "\n",
    "# Printing the results\n",
    "print(\"Decision Tree Classifier with the top 6 features\")\n",
    "print(\"Model: \", Tree_model_6)\n",
    "print(\"Score: \", round(Tree_score_6, 3))\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "# Extracting the best model\n",
    "Tree_model_7 = tree_grid_search_7.best_estimator_\n",
    "Tree_score_7 = tree_grid_search_7.cv_results_\n",
    "Tree_score_7 = Tree_score_7['mean_test_score'][0]\n",
    "\n",
    "# Printing the results\n",
    "print(\"Decision Tree Classifier with the top 7 features\")\n",
    "print(\"Model: \", Tree_model_7)\n",
    "print(\"Score: \", round(Tree_score_7, 3))\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "# Extracting the best model\n",
    "Tree_model_8 = tree_grid_search_8.best_estimator_\n",
    "Tree_score_8 = tree_grid_search_8.cv_results_\n",
    "Tree_score_8 = Tree_score_8['mean_test_score'][0]\n",
    "\n",
    "# Printing the results\n",
    "print(\"Decision Tree Classifier with the top 8 features\")\n",
    "print(\"Model: \", Tree_model_8)\n",
    "print(\"Score: \", round(Tree_score_8, 3))\n",
    "print(\" \")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
